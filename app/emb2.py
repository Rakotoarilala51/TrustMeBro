from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

# 1Ô∏è‚É£ Charger le mod√®le √† partir du dossier local
embedding_function = HuggingFaceEmbeddings(
    model_name="./ai-models/all-MiniLM-L6-v2"
)

# 2Ô∏è‚É£ Initialiser Chroma
vectorstore = Chroma(
    collection_name="cv_collection",
    embedding_function=embedding_function,
    persist_directory="./chromadb"  # R√©pertoire pour persister
)

# 3Ô∏è‚É£ Ajouter des textes (exemple CVs)
cv_1 = "Backend Developer with Python, FastAPI, and PostgreSQL experience."
cv_2 = "Frontend Engineer with React, TypeScript, and UI/UX skills."

vectorstore.add_texts(
    texts=[cv_1, cv_2],
    metadatas=[
        {"filename": "cv_john.txt"},
        {"filename": "cv_jane.txt"}
    ]
)

# 4Ô∏è‚É£ Sauvegarder la base
vectorstore.persist()
print("‚úÖ Embeddings cr√©√©s et stock√©s localement.")

# 5Ô∏è‚É£ Exemple de recherche
job_offer = "Looking for a Python developer with FastAPI skills"
results = vectorstore.similarity_search(job_offer, k=2)

print("\nüîé R√©sultats :")
for res in results:
    print("üìÑ Fichier :", res.metadata["filename"])
    print("üìù Contenu :", res.page_content)
